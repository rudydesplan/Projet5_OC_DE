
# üè• Healthcare CSV ‚Üí MongoDB Loader

Ce projet fournit un pipeline **robuste, test√©, dockeris√© et extensible** pour charger des donn√©es patients depuis un fichier CSV vers une base MongoDB.

---

## üöÄ Fonctionnalit√©s principales

- üß© **Sch√©ma BSON JSON valid√©** automatiquement
- üì¶ **Index MongoDB optimis√©s**
- üìÇ **Insertion batch via `bulk_write` (rapide et r√©siliente)**
- üìÜ **Conversion temporelle timezone-aware** avec `pendulum`
- üß™ **Tests unitaires isol√©s avec `pytest + mongomock`**
- üìä **Contr√¥les d'int√©grit√© avant / apr√®s migration**
- üê≥ **Conteneurisation compl√®te via Docker & Docker Compose**
- üõ† **Automatisation via `Makefile`**

---

## üóÇ Arborescence du projet

```bash
project-root/
‚îú‚îÄ‚îÄ Makefile                    ‚Üê Commandes rapides
‚îú‚îÄ‚îÄ docker-compose.yml          ‚Üê Orchestration Mongo + App
‚îú‚îÄ‚îÄ README.md                   ‚Üê Ce fichier
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              ‚Üê Image de l'application
‚îÇ   ‚îú‚îÄ‚îÄ healthcare_mongo_loader_optimized.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ healthcare_dataset.csv
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ test_healthcare_loader.py
```

---

## üß≠ √âtapes de la migration

### 1. Connexion MongoDB

```python
MongoClient("mongodb://localhost:27017", tz_aware=True)
```

> Le flag `tz_aware` permet d‚Äôinteragir avec des objets `datetime` conscients du fuseau horaire.

### 2. Cr√©ation / Mise √† jour de la collection

- Si la collection `Patients` n‚Äôexiste pas ‚Üí **cr√©ation + sch√©ma JSON appliqu√©**
- Si elle existe ‚Üí **mise √† jour du sch√©ma sans suppression** via `collMod` :

```python
db.command({
  "collMod": "Patients",
  "validator": {"$jsonSchema": patient_schema},
  "validationLevel": "strict",
  "validationAction": "error"
})
```

### 3. Chargement du CSV

- Lecture `pandas`
- Nettoyage des champs texte : capitalisation, formatage sang/gender/type...
- Transformation explicite des types :
  - `int` (√¢ge, room)
  - `float` (billing)
  - `pendulum.parse(...)` pour les dates ‚Üí converties na√Øves UTC
- Insertion par batch :
  - Par d√©faut `batch_size = 2000`
  - Insertions via `bulk_write(InsertOne(...))` d√©sordonn√©es (`ordered=False`)

### 4. Index MongoDB automatiques

| Champs                              | Type d‚Äôindex | Utilit√© principale                               |
|------------------------------------|--------------|--------------------------------------------------|
| `["Date of Admission"]`            | Simple       | Requ√™tes temporelles, tendances hospitali√®res    |
| `["Discharge Date"]`               | Simple       | Dur√©es moyennes, taux de sortie                  |
| `["Medical Condition"]`            | Simple       | Analyses sant√© par pathologie                    |
| `["Hospital", "Admission Type"]`   | Compos√©      | Requ√™tes par √©tablissement et type d‚Äôadmission   |
| `["Doctor"]`                       | Simple       | Regroupement par m√©decin                         |

> ‚ùó Pas d‚Äôunicit√© sur `"Name"` ou `"Name + Date"` pour √©viter les faux positifs (doublons l√©gitimes).

### 5. Journalisation avec `loguru`

- Logs en console + fichiers rotatifs (`500 KB`, retention 5 jours)
- Niveaux : `INFO`, `SUCCESS`, `WARNING`, `ERROR`

---

## ‚úÖ Tests automatis√©s (avec `pytest + mongomock`)

```bash
make test
```

| Test                                      | Description                                                                 |
|------------------------------------------|-----------------------------------------------------------------------------|
| `test_create_schema`                     | Cr√©ation et structure du sch√©ma MongoDB                                    |
| `test_load_data_transformation`          | Transformation correcte des types et standardisation texte                  |
| `test_schema_rejects_invalid_doc`        | Rejet des documents invalides (ex : champ requis manquant)                 |
| `test_batch_logging_and_processing`      | Log et fonctionnement du traitement par lots                              |
| `test_malformed_csv_logs_error`          | D√©tection d‚Äôerreurs de type (ex : √¢ge non entier)                          |
| `test_partial_schema_doc`                | Insertion avec champ en surplus (tol√©r√©)                                   |
| `test_gender_capitalization`             | Capitalisation coh√©rente des champs texte                                  |
| `test_date_parsing`                      | Conversion correcte des dates                                              |
| `test_data_integrity_against_schema`     | Colonnes CSV pr√©sentes, non nulles, coh√©rence Mongo                        |
| `test_no_null_fields_after_migration`    | Champs requis non null dans MongoDB                                        |
| `test_csv_and_mongo_count_match`         | Nombre de lignes ins√©r√©es == lignes du CSV                                 |
| `test_empty_csv`                         | Fichier CSV vide logu√© proprement                                          |

---

## üß™ Validation d'int√©grit√© des donn√©es

- üìë Colonnes pr√©sentes
- üî¢ Types conformes (`int`, `float`, `date`, `str`)
- üö´ Champs requis non nuls
- ‚ôªÔ∏è Absence de doublons (`Name` + `Date of Admission`)
- üßº Normalisation cha√Ænes (`Gender`, `Blood Type`, etc.)

---

## üì¶ Dockerisation

### Dockerfile

L‚Äôimage installe :

* Python 3
* Les d√©pendances (pandas, pymongo, loguru, pendulum)
* Monte le volume `/app/data` contenant le CSV
* Ex√©cute le script √† l‚Äôentr√©e du conteneur

### docker-compose.yml

Lance deux services :

* `mongo` (conteneur MongoDB)
* `app` (notre script)

```yaml
volumes:
  mongo_data:
  csv_data:

services:
  mongo:
    image: mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  app:
    build: ./app
    volumes:
      - ./app/data:/app/data
    depends_on:
      - mongo
    environment:
      - MONGO_URI=mongodb://mongo:27017
```

---

## ‚öôÔ∏è Makefile

```makefile
build:
	docker compose build

up:
	docker compose up

down:
	docker compose down

test:
	pytest -v test/test_healthcare_loader.py
```

---

## üìÇ Fichiers cl√©s

| Fichier                            | R√¥le                                                                 |
|-----------------------------------|----------------------------------------------------------------------|
| `healthcare_mongo_loader_optimized.py` | Script principal                                                     |
| `test_healthcare_loader.py`       | Suite de tests Pytest                                                |
| `Healthcare_Dataset_Dictionary.csv` | Dictionnaire des colonnes                                            |
| `Dockerfile`                      | Image de l‚Äôapp                                                       |
| `docker-compose.yml`              | Orchestration Mongo + App                                            |
| `Makefile`                        | Automatisation                                                        |

---

## ‚ñ∂Ô∏è Lancer la migration compl√®te


```bash
make build
make up
```

* V√©rifie que `healthcare_dataset.csv` est bien dans `app/data/`
* Tu peux suivre les logs :

  ```bash
  docker compose logs -f app
  ```


---

## üßº Nettoyage

```bash
make down
docker volume prune -f
```

---

## üìã Notes techniques

* Insertion via `bulk_write` en mode **non ordonn√©** (`ordered=False`) pour :

  * am√©liorer les performances
  * √©viter l‚Äô√©chec complet en cas d‚Äôerreur dans un document

* Les dates sont converties via `pendulum` avec UTC par d√©faut :

  ```python
  pendulum.parse(...).naive()
  ```

---

## üë®‚Äçüíª Auteur

Rudy Desplan ‚Äì Data Engineer
